Lab Exercise: Language Model Evaluation
Write your own implementation of the Stupid backoff algorithm. Train it and compare the perplexity with the one provided by NLKT. The dataset that you have to use is the Shakespeare Macbeth.

Stupid Backoff algorithm (use ‚ç∫=0.4): https://aclanthology.org/D07-1090.pdf

NLTK (StupidBackoff): https://www.nltk.org/api/nltk.lm.html

OUTPUT:

[nltk_data] Downloading package gutenberg to C:\Users\Mateo-
[nltk_data]     drr\AppData\Roaming\nltk_data...
[nltk_data]   Package gutenberg is already up-to-date!
[nltk_data] Downloading package punkt to C:\Users\Mateo-
[nltk_data]     drr\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!

NLTK IMPLEMENTATION
Entropy: 6.340725337129417
Perplexity: 81.04916048476649

CUSTOM IMPLEMENTATION:
Entropy: 6.340725337129417
Perplexity: 81.04916048476649
